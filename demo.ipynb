{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSM-MetaRL-Unified Demo: Experience-Augmented Meta-RL\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sunghunkwag/SSM-MetaRL-Unified/blob/main/demo.ipynb)\n",
    "\n",
    "This notebook demonstrates the **SSM-MetaRL-Unified** framework, which integrates:\n",
    "- **State Space Models (SSM)** for efficient sequence modeling\n",
    "- **Meta-Learning (MAML)** for fast adaptation\n",
    "- **Standard Test-Time Adaptation** (baseline)\n",
    "- **Hybrid Test-Time Adaptation** with **Experience Replay** (novel approach)\n",
    "\n",
    "## Key Innovation\n",
    "\n",
    "The unified framework allows you to compare two adaptation strategies:\n",
    "1. **Standard Mode**: Adapts using only current task data\n",
    "2. **Hybrid Mode**: Augments adaptation with past experiences from a replay buffer\n",
    "\n",
    "The hybrid approach can lead to more robust and sample-efficient learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Install required dependencies and clone the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch numpy gymnasium matplotlib -q\n",
    "\n",
    "# Clone the unified repository\n",
    "import os\n",
    "if not os.path.exists('SSM-MetaRL-Unified'):\n",
    "    !git clone https://github.com/sunghunkwag/SSM-MetaRL-Unified.git\n",
    "    os.chdir('SSM-MetaRL-Unified')\n",
    "else:\n",
    "    os.chdir('SSM-MetaRL-Unified')\n",
    "\n",
    "print(\"✓ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules\n",
    "\n",
    "Import all necessary components from the unified framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "\n",
    "# Import unified framework components\n",
    "from core.ssm import StateSpaceModel\n",
    "from meta_rl.meta_maml import MetaMAML\n",
    "from adaptation import StandardAdapter, StandardAdaptationConfig\n",
    "from adaptation import HybridAdapter, HybridAdaptationConfig\n",
    "from experience.experience_buffer import ExperienceBuffer\n",
    "from env_runner.environment import Environment\n",
    "\n",
    "print(\"✓ Imports successful!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Environment and Model\n",
    "\n",
    "Initialize the CartPole environment and create the SSM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "env_name = 'CartPole-v1'\n",
    "state_dim = 32\n",
    "hidden_dim = 64\n",
    "\n",
    "# Initialize environment\n",
    "env = Environment(env_name=env_name, batch_size=1)\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = input_dim  # Predict next observation\n",
    "\n",
    "print(f\"Environment: {env_name}\")\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "print(f\"Output dimension: {output_dim}\")\n",
    "\n",
    "# Create SSM model\n",
    "model = StateSpaceModel(\n",
    "    state_dim=state_dim,\n",
    "    input_dim=input_dim,\n",
    "    output_dim=output_dim,\n",
    "    hidden_dim=hidden_dim\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\n✓ Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Meta-Training with MetaMAML\n",
    "\n",
    "Train the model using MetaMAML to enable fast adaptation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectory(env, model, num_steps=50, device='cpu'):\n",
    "    \"\"\"Collect a trajectory from the environment.\"\"\"\n",
    "    observations = []\n",
    "    next_observations = []\n",
    "    \n",
    "    obs = env.reset()\n",
    "    hidden_state = model.init_hidden(batch_size=1)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden_state = model(obs_tensor, hidden_state)\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        observations.append(obs)\n",
    "        next_observations.append(next_obs)\n",
    "        \n",
    "        obs = next_obs\n",
    "        if done:\n",
    "            obs = env.reset()\n",
    "            hidden_state = model.init_hidden(batch_size=1)\n",
    "    \n",
    "    # Convert to tensors with shape (1, T, D)\n",
    "    obs_seq = torch.tensor(np.array(observations), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    next_obs_seq = torch.tensor(np.array(next_observations), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    return obs_seq, next_obs_seq\n",
    "\n",
    "# Meta-training\n",
    "print(\"Starting meta-training...\")\n",
    "meta_learner = MetaMAML(model=model, inner_lr=0.01, outer_lr=0.001)\n",
    "meta_losses = []\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Collect support and query data\n",
    "    obs_support, next_obs_support = collect_trajectory(env, model, num_steps=50, device=device)\n",
    "    obs_query, next_obs_query = collect_trajectory(env, model, num_steps=50, device=device)\n",
    "    \n",
    "    # Create tasks list\n",
    "    tasks = [(obs_support, next_obs_support, obs_query, next_obs_query)]\n",
    "    \n",
    "    # Meta-update\n",
    "    initial_hidden = model.init_hidden(batch_size=1)\n",
    "    loss = meta_learner.meta_update(\n",
    "        tasks=tasks,\n",
    "        initial_hidden_state=initial_hidden,\n",
    "        loss_fn=nn.MSELoss()\n",
    "    )\n",
    "    \n",
    "    meta_losses.append(loss)\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Meta Loss = {loss:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Meta-training completed!\")\n",
    "\n",
    "# Plot meta-training loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(meta_losses, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Meta Loss')\n",
    "plt.title('Meta-Training Progress')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test-Time Adaptation: Standard Mode\n",
    "\n",
    "Test the standard adaptation approach (baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Standard Adaptation Mode...\")\n",
    "\n",
    "# Create standard adapter\n",
    "standard_config = StandardAdaptationConfig(\n",
    "    learning_rate=0.01,\n",
    "    num_steps=5\n",
    ")\n",
    "standard_adapter = StandardAdapter(\n",
    "    model=model,\n",
    "    config=standard_config,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Test adaptation\n",
    "obs = env.reset()\n",
    "hidden_state = model.init_hidden(batch_size=1)\n",
    "standard_losses = []\n",
    "\n",
    "num_adapt_steps = 20\n",
    "for step in range(num_adapt_steps):\n",
    "    obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, next_hidden_state = model(obs_tensor, hidden_state)\n",
    "        action = env.action_space.sample()\n",
    "    \n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    next_obs_tensor = torch.tensor(next_obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Perform adaptation\n",
    "    loss_val, _ = standard_adapter.update_step(\n",
    "        x=obs_tensor,\n",
    "        y=next_obs_tensor,\n",
    "        hidden_state=hidden_state\n",
    "    )\n",
    "    \n",
    "    standard_losses.append(loss_val)\n",
    "    \n",
    "    obs = next_obs\n",
    "    hidden_state = next_hidden_state\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        hidden_state = model.init_hidden(batch_size=1)\n",
    "\n",
    "print(f\"✓ Standard adaptation completed!\")\n",
    "print(f\"  Initial loss: {standard_losses[0]:.4f}\")\n",
    "print(f\"  Final loss: {standard_losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {(1 - standard_losses[-1]/standard_losses[0])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test-Time Adaptation: Hybrid Mode (Experience-Augmented)\n",
    "\n",
    "Now test the hybrid adaptation with experience replay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing Hybrid Adaptation Mode (with Experience Replay)...\")\n",
    "\n",
    "# Initialize experience buffer\n",
    "experience_buffer = ExperienceBuffer(max_size=1000, device=str(device))\n",
    "print(f\"Initialized ExperienceBuffer (max_size=1000)\")\n",
    "\n",
    "# Populate buffer with some initial experiences\n",
    "print(\"Populating experience buffer...\")\n",
    "for _ in range(5):\n",
    "    obs_traj, next_obs_traj = collect_trajectory(env, model, num_steps=20, device=device)\n",
    "    # Add to buffer (flatten time dimension)\n",
    "    for t in range(obs_traj.shape[1]):\n",
    "        experience_buffer.add(\n",
    "            obs_traj[:, t, :],\n",
    "            next_obs_traj[:, t, :]\n",
    "        )\n",
    "\n",
    "print(f\"Buffer populated with {len(experience_buffer)} experiences\")\n",
    "\n",
    "# Create hybrid adapter\n",
    "hybrid_config = HybridAdaptationConfig(\n",
    "    learning_rate=0.01,\n",
    "    num_steps=5,\n",
    "    experience_batch_size=16,\n",
    "    experience_weight=0.1\n",
    ")\n",
    "hybrid_adapter = HybridAdapter(\n",
    "    model=model,\n",
    "    config=hybrid_config,\n",
    "    experience_buffer=experience_buffer,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Test adaptation\n",
    "obs = env.reset()\n",
    "hidden_state = model.init_hidden(batch_size=1)\n",
    "hybrid_losses = []\n",
    "\n",
    "num_adapt_steps = 20\n",
    "for step in range(num_adapt_steps):\n",
    "    obs_tensor = torch.tensor(obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output, next_hidden_state = model(obs_tensor, hidden_state)\n",
    "        action = env.action_space.sample()\n",
    "    \n",
    "    next_obs, reward, done, info = env.step(action)\n",
    "    next_obs_tensor = torch.tensor(next_obs, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Perform hybrid adaptation (uses experience replay)\n",
    "    loss_val, _ = hybrid_adapter.update_step(\n",
    "        x_current=obs_tensor,\n",
    "        y_current=next_obs_tensor,\n",
    "        hidden_state_current=hidden_state\n",
    "    )\n",
    "    \n",
    "    hybrid_losses.append(loss_val)\n",
    "    \n",
    "    obs = next_obs\n",
    "    hidden_state = next_hidden_state\n",
    "    \n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "        hidden_state = model.init_hidden(batch_size=1)\n",
    "\n",
    "print(f\"✓ Hybrid adaptation completed!\")\n",
    "print(f\"  Initial loss: {hybrid_losses[0]:.4f}\")\n",
    "print(f\"  Final loss: {hybrid_losses[-1]:.4f}\")\n",
    "print(f\"  Improvement: {(1 - hybrid_losses[-1]/hybrid_losses[0])*100:.1f}%\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparison: Standard vs. Hybrid Adaptation\n",
    "\n",
    "Visualize the difference between the two adaptation strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(standard_losses, marker='o', label='Standard', color='blue', alpha=0.7)\n",
    "plt.plot(hybrid_losses, marker='s', label='Hybrid (Experience-Augmented)', color='red', alpha=0.7)\n",
    "plt.xlabel('Adaptation Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Adaptation Loss Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "methods = ['Standard', 'Hybrid']\n",
    "initial_losses = [standard_losses[0], hybrid_losses[0]]\n",
    "final_losses = [standard_losses[-1], hybrid_losses[-1]]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, initial_losses, width, label='Initial Loss', alpha=0.7)\n",
    "plt.bar(x + width/2, final_losses, width, label='Final Loss', alpha=0.7)\n",
    "plt.xlabel('Adaptation Mode')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Initial vs. Final Loss')\n",
    "plt.xticks(x, methods)\n",
    "plt.legend()\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Standard Mode:\")\n",
    "print(f\"  Loss reduction: {(1 - standard_losses[-1]/standard_losses[0])*100:.1f}%\")\n",
    "print(f\"\\nHybrid Mode (Experience-Augmented):\")\n",
    "print(f\"  Loss reduction: {(1 - hybrid_losses[-1]/hybrid_losses[0])*100:.1f}%\")\n",
    "print(f\"  Buffer size: {len(experience_buffer)} experiences\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This demo showcased the **SSM-MetaRL-Unified** framework's dual adaptation capabilities:\n",
    "\n",
    "1. **Standard Adaptation**: Uses only current task data for adaptation (baseline approach)\n",
    "2. **Hybrid Adaptation**: Augments adaptation with past experiences from a replay buffer (novel approach)\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- The **ExperienceBuffer** enables the model to learn from past trajectories during adaptation\n",
    "- The **hybrid loss** combines current data with sampled experiences for more robust learning\n",
    "- This approach can be particularly beneficial in:\n",
    "  - Sparse reward environments\n",
    "  - Non-stationary tasks\n",
    "  - Sample-limited scenarios\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different buffer sizes and experience weights\n",
    "- Test on more complex environments\n",
    "- Run SOTA benchmarks on MuJoCo tasks\n",
    "- Compare against LSTM, GRU, and Transformer baselines\n",
    "\n",
    "For more information, visit the [GitHub repository](https://github.com/sunghunkwag/SSM-MetaRL-Unified)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

