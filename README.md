# SSM-MetaRL-Unified

**State Space Model + Meta-Reinforcement Learning with Test-Time Adaptation**

A complete implementation combining State Space Models (SSM) with Meta-RL (MAML) for fast adaptation to new tasks.

[![Hugging Face Space](https://img.shields.io/badge/ğŸ¤—%20Hugging%20Face-Space-blue)](https://huggingface.co/spaces/stargatek1/SSM-MetaRL-Unified)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸš€ Features

- âœ… **State Space Model (SSM)** architecture for temporal modeling
- âœ… **Meta-Learning with MAML** for fast adaptation
- âœ… **Standard test-time adaptation** using current task data
- âœ… **Hybrid adaptation** with experience replay buffer
- âœ… **Gradio web interface** for interactive experimentation
- âœ… **Original research implementation** maintained

## ğŸ¯ What is SSM-MetaRL?

This project combines two powerful concepts:

1. **State Space Models (SSM)**: Efficient sequential modeling with hidden state
2. **Meta-Reinforcement Learning (MAML)**: Learning to learn for fast adaptation

The result is an agent that can:
- Learn from multiple tasks during meta-training
- Quickly adapt to new tasks with minimal data
- Leverage past experiences for better adaptation

## ğŸ“¦ Installation

```bash
# Clone the repository
git clone https://github.com/sunghunkwag/SSM-MetaRL-Unified.git
cd SSM-MetaRL-Unified

# Install dependencies
pip install torch gymnasium numpy gradio
```

## ğŸƒ Quick Start

### Web Interface (Recommended)

Launch the Gradio interface:

```bash
python app.py
```

Then open http://localhost:7860 in your browser.

### Command Line

Meta-training with MAML:

```bash
python main.py \
    --mode meta_rl \
    --env_name CartPole-v1 \
    --num_epochs 100 \
    --tasks_per_epoch 5 \
    --inner_lr 0.01 \
    --outer_lr 0.001
```

Policy gradient training:

```bash
python main.py \
    --mode policy_gradient \
    --env_name CartPole-v1 \
    --num_episodes 200
```

## ğŸŒ Try it Online

**[ğŸ¤— Hugging Face Space](https://huggingface.co/spaces/stargatek1/SSM-MetaRL-Unified)**

No installation required! Try the model directly in your browser.

## ğŸ—ï¸ Architecture

### State Space Model (SSM)

```
Input (observation) â†’ SSM Block â†’ Output (actions/predictions)
                         â†“
                   Hidden State (recurrent)
```

**Components:**
- State transition network (A matrix)
- Input projection (B matrix)
- Output network (C matrix)
- Feedthrough connection (D matrix)

### Meta-Learning (MAML)

**Inner Loop (Task Adaptation):**
1. Collect support set from task
2. Perform gradient steps on support set
3. Obtain adapted parameters

**Outer Loop (Meta-Update):**
1. Evaluate adapted parameters on query set
2. Compute meta-loss
3. Update meta-parameters

### Test-Time Adaptation

**Standard Mode:**
- Uses only current task observations
- Simple and fast baseline

**Hybrid Mode:**
- Combines current observations + experience replay
- More robust adaptation
- Original research contribution

## ğŸ“Š Performance

**CartPole-v1:**
- Meta-training: 100 epochs, 5 tasks/epoch
- Zero-shot: 20-40 reward
- After adaptation: 40-80 reward
- Clear meta-learning benefit

## ğŸ“ Project Structure

```
SSM-MetaRL-Unified/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ ssm.py              # State Space Model
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ meta_rl/
â”‚   â”œâ”€â”€ meta_maml.py        # MAML algorithm
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ adaptation/
â”‚   â”œâ”€â”€ standard_adapter.py # Standard adaptation
â”‚   â”œâ”€â”€ hybrid_adapter.py   # Hybrid adaptation
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ experience/
â”‚   â”œâ”€â”€ experience_buffer.py # Experience replay
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ env_runner/
â”‚   â”œâ”€â”€ environment.py      # Gym wrapper
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ app.py                  # Gradio interface
â”œâ”€â”€ main.py                 # Training script
â””â”€â”€ README.md
```

## ğŸ”¬ Key Concepts

### Meta-Learning
Learning to learn - finding good initialization for fast adaptation.

### MAML
Model-Agnostic Meta-Learning through gradient descent.

### State Space Models
Efficient sequential models with hidden state for temporal dependencies.

### Experience Replay
Storing and reusing past experiences for better learning.

## ğŸ“ Research Background

Based on:
- [MAML Paper](https://arxiv.org/abs/1703.03400)
- [Meta-RL Survey](https://arxiv.org/abs/1910.03193)
- [State Space Models](https://arxiv.org/abs/2111.00396)

## ğŸ“ License

MIT License

## ğŸ™ Acknowledgments

- MAML algorithm by Finn et al.
- Gymnasium for RL environments
- Gradio for web interface

## ğŸ”— Links

- **Hugging Face**: https://huggingface.co/spaces/stargatek1/SSM-MetaRL-Unified
- **GitHub**: https://github.com/sunghunkwag/SSM-MetaRL-Unified

---

**Made with â¤ï¸ for the Meta-RL community**

